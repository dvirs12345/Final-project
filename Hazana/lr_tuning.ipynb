{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "855d1bd2aad044e8623f1067f1bf07fd90360221"
   },
   "source": [
    "# Objective:\n",
    "recognize  the fashion object   on Mnist dataset with the help of PCA and GridSearchCV\n",
    "https://www.kaggle.com/zalando-research/fashionmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ser_num</th>\n",
       "      <th>ICU_LOS</th>\n",
       "      <th>LOS_Group</th>\n",
       "      <th>ICU_mortality</th>\n",
       "      <th>HOSP_mortality</th>\n",
       "      <th>28_mortality</th>\n",
       "      <th>90 days mortality</th>\n",
       "      <th>trauma</th>\n",
       "      <th>metabolic</th>\n",
       "      <th>gastrointestinal</th>\n",
       "      <th>...</th>\n",
       "      <th>EN_pro_day12</th>\n",
       "      <th>PN_pro_day12</th>\n",
       "      <th>EN_pro_day13</th>\n",
       "      <th>PN_pro_day13</th>\n",
       "      <th>EN_pro_day0/kg</th>\n",
       "      <th>EN_pro_day1/kg</th>\n",
       "      <th>EN_pro_day2/kg</th>\n",
       "      <th>EN_pro_day3/kg</th>\n",
       "      <th>EN_pro_day4/kg</th>\n",
       "      <th>EN_pro_day5/kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>LOS_8-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250297</td>\n",
       "      <td>1.221456</td>\n",
       "      <td>1.578462</td>\n",
       "      <td>0.995015</td>\n",
       "      <td>1.394308</td>\n",
       "      <td>1.403077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LOS_5-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.758495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670993</td>\n",
       "      <td>1.177788</td>\n",
       "      <td>0.403229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>LOS_8-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.273355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>1.396370</td>\n",
       "      <td>0.256457</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>LOS_5-7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145278</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.209667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>LOS_8-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014902</td>\n",
       "      <td>0.858353</td>\n",
       "      <td>0.731984</td>\n",
       "      <td>0.922729</td>\n",
       "      <td>1.287529</td>\n",
       "      <td>1.287529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ser_num  ICU_LOS LOS_Group  ICU_mortality  HOSP_mortality  28_mortality  \\\n",
       "0        2        9  LOS_8-13              0               0             0   \n",
       "1        3        5   LOS_5-7              0               0             0   \n",
       "2        5       13  LOS_8-13              0               0             0   \n",
       "3        7        6   LOS_5-7              0               0             0   \n",
       "4        9        9  LOS_8-13              0               0             0   \n",
       "\n",
       "   90 days mortality  trauma  metabolic  gastrointestinal  ...  EN_pro_day12  \\\n",
       "0                  0       0          1                 0  ...           0.0   \n",
       "1                  0       0          1                 0  ...           0.0   \n",
       "2                  0       0          0                 1  ...           0.0   \n",
       "3                  0       0          1                 1  ...           0.0   \n",
       "4                  0       1          1                 1  ...           0.0   \n",
       "\n",
       "  PN_pro_day12 EN_pro_day13  PN_pro_day13  EN_pro_day0/kg  EN_pro_day1/kg  \\\n",
       "0     0.000000          0.0           0.0        1.250297        1.221456   \n",
       "1     0.000000          0.0           0.0        0.758495        0.000000   \n",
       "2    53.273355          0.0           0.0        0.000000        0.000000   \n",
       "3     0.000000          0.0           0.0        1.145278        1.520000   \n",
       "4     0.000000          0.0           0.0        0.014902        0.858353   \n",
       "\n",
       "  EN_pro_day2/kg EN_pro_day3/kg EN_pro_day4/kg  EN_pro_day5/kg  \n",
       "0       1.578462       0.995015       1.394308        1.403077  \n",
       "1       0.670993       1.177788       0.403229        0.000000  \n",
       "2       0.023259       1.396370       0.256457        0.000000  \n",
       "3       1.520000       1.520000       1.520000        1.209667  \n",
       "4       0.731984       0.922729       1.287529        1.287529  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import random\n",
    "  \n",
    "dataset=pd.read_excel(\"C:/Users/97254/Downloads/patient_new.xlsx\", engine='openpyxl')\n",
    "\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NAN\n",
    "dataset = dataset[~dataset['age'].isin(['NAN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[\n",
    "    'ICU_mortality',\n",
    " 'LOS_Group',\n",
    "'trauma',\n",
    "'metabolic',\n",
    "'gastrointestinal',\n",
    "'Sepsis'\n",
    ",'age'\n",
    ",'gender'\n",
    ",'weight'\n",
    ",'BMI'\n",
    ",'active problems'\n",
    ",'background problems'\n",
    ",'feeding'\n",
    ",'Target_pro_day'\n",
    ",'pro_to_target_day0'\n",
    ",'pro_to_target_day1'\n",
    ",'pro_to_target_day2'\n",
    ",'pro_to_target_day3'\n",
    ",'pro_to_target_day4'\n",
    ",'pro_to_target_day5'\n",
    ",'pro_to_target_day6'\n",
    ",'pro_to_target_day7'\n",
    ",'pro_to_target_day8'\n",
    ",'pro_to_target_day9'\n",
    ",'pro_to_target_day10'\n",
    ",'pro_to_target_day11'\n",
    ",'pro_to_target_day12'\n",
    ",'pro_to_target_day13'\n",
    ",'Total_EN_pro'\n",
    ",'Total_PN_pro'\n",
    ",'EN_pro_day0'\n",
    ",'PN_pro_day0'\n",
    ",'EN_pro_day1'\n",
    ",'PN_pro_day1'\n",
    ",'EN_pro_day2'\n",
    ",'PN_pro_day2'\n",
    ",'EN_pro_day3'\n",
    ",'PN_pro_day3'\n",
    ",'EN_pro_day4'\n",
    ",'PN_pro_day4'\n",
    ",'EN_pro_day5'\n",
    ",'PN_pro_day5'\n",
    ",'EN_pro_day6'\n",
    ",'PN_pro_day6'\n",
    ",'EN_pro_day7'\n",
    ",'PN_pro_day7'\n",
    ",'EN_pro_day8'\n",
    ",'PN_pro_day8'\n",
    ",'EN_pro_day9'\n",
    ",'PN_pro_day9'\n",
    ",'EN_pro_day10'\n",
    ",'PN_pro_day10'\n",
    ",'EN_pro_day11'\n",
    ",'PN_pro_day11'\n",
    ",'EN_pro_day12'\n",
    ",'PN_pro_day12'\n",
    ",'EN_pro_day13'\n",
    ",'PN_pro_day13'  \n",
    ",'EN_pro_day0/kg'   \n",
    ",'EN_pro_day1/kg'    \n",
    ",'EN_pro_day2/kg'      \n",
    ",'EN_pro_day3/kg'    \n",
    ",'EN_pro_day4/kg'       \n",
    ",'EN_pro_day5/kg'        \n",
    "    \n",
    "]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "dataset['active problems'] = le.fit_transform(dataset['active problems'].astype(str))\n",
    "dataset['background problems'] = le.fit_transform(dataset['background problems'].astype(str))\n",
    "dataset['gender'] = le.fit_transform(dataset['gender'].astype(str))\n",
    "dataset['feeding'] = le.fit_transform(dataset['feeding'].astype(str))\n",
    "dataset['LOS_Group'] = le.fit_transform(dataset['feeding'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "152e7aa03b0a79e04e1678623dd46f578e0a189a"
   },
   "source": [
    "### GridSearch Cross Validation\n",
    "In machine learning, two tasks are commonly done at the same time in data pipelines: cross validation and (hyper)parameter tuning. Cross validation is the process of training learners using one set of data and testing it using a different set. Parameter tuning is the process to selecting the values for a modelâ€™s parameters that maximize the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 150 | elapsed:    1.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:    1.5s finished\n",
      "c:\\users\\97254\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1353: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# making skeletal model\n",
    "logistic_regression = LogisticRegression(n_jobs = -1)\n",
    "\n",
    "# Set of parameters we want to try for our Model\n",
    "#Regularization normally tries to reduce or penalize the complexity of the model.\n",
    "#Regularization techniques applied with logistic regression mostly tend to penalize large coefficients\n",
    "parameters = { 'C' : [0.00001,0.01,0.1,0.5,1.1]\n",
    ",'penalty': ['l1', 'l2'],\n",
    "   # 'max_iter': list(range(100,800,100)),\n",
    "   'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "             }\n",
    "#Running the Model with above chosen parameter\n",
    "grid_search = GridSearchCV(estimator = logistic_regression, param_grid = parameters , scoring = 'accuracy', cv = 3, n_jobs = -1 , verbose = 2)\n",
    "grid_scores = grid_search.fit(dataset.iloc[:,1:] , dataset.iloc[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7817745803357314\n",
      "{'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print( grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#this function randomly split the data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset.iloc[:,1:] , dataset.iloc[:,0], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training a Logistic Regression model = 0:00:00.048035\n"
     ]
    }
   ],
   "source": [
    "# Making the Final Classification model.\n",
    "import datetime\n",
    "logistic_regression = LogisticRegression( C = 0.01, n_jobs = -1)\n",
    "tick =datetime.datetime.now()\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "tock=datetime.datetime.now()\n",
    "lr_train_time = tock - tick\n",
    "print(\"Time taken for training a Logistic Regression model = \" + str(lr_train_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13e0259d0af556b7f3fb51ebea80eeea5f769834"
   },
   "source": [
    "## 8. Predicting values on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict the data points in the Test set is : 0:00:00.008027\n"
     ]
    }
   ],
   "source": [
    "tick=datetime.datetime.now()\n",
    "lr_train_predict=logistic_regression.predict(x_test)\n",
    "tock=datetime.datetime.now()\n",
    "lr_pred_train_time = tock - tick\n",
    "print('Time taken to predict the data points in the Test set is : ' + str(lr_pred_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       131\n",
      "           1       0.44      0.11      0.18        36\n",
      "\n",
      "    accuracy                           0.78       167\n",
      "   macro avg       0.62      0.54      0.52       167\n",
      "weighted avg       0.72      0.78      0.72       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "print(skm.classification_report( y_test, lr_train_predict ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,   5],\n",
       "       [ 32,   4]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf= confusion_matrix(y_test, lr_train_predict )\n",
    "\n",
    "# Visualizing the Confusion Matrix`\n",
    "cf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
